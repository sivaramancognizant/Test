# Automated Code Quality Checking

The Cognizant or Customer environment will provide automatic code quality checking capability through the use of tools, such as SONARQUBE, and a number of rules preconfigured on the platform to work with the Customer source control system. The objective of which is to drive up code quality and ensure sustainability on the Customer platform as multiple projects look to deliver into a single ORG. The use of these tools is supplemental to peer reviews and quality checks in projects

More details regarding this can be found within the associated tooling guides and documentation. However within the coding standards we highlight a couple of exception use cases to developers to ensure transparency and clarity in this area or advise where we have made changes to the default settings in the quality tool rules for information.
### Confusing Ternary

For long term maintainability and viability code must be readable and clear for parties external to a project to understand. Initial set of rules regarding confusing ternary were set so that errors of this type are deemed major. This has been revised in the case of direct examples using IF statements of which there are many ways to write them.

Ideally in an if expression with an else clause, avoid negation in the test. For example, rephrase: if (x != y) diff(); else same(); as: if (x == y) same(); else diff(); Most if (x != y) cases without an else are often return cases, so consistent use of this rule makes the code easier to read.

Given the above the prevailing view is that this is a MINOR rule infringement rather than a MAJOR.

### Avoid JavaScript script lets

Upon review the limit in the scanning tools is increased to 20 lines. It is expected that peer reviews will cover the rest of the gap in projects.
### Image tags should always have a “width” & “height” attribute

This has been set to info only as a code checking rule.

###	Unused local variable/private field

Where false positives are generated by the code scanning tool these will be ignored.

However on a case by case basis for other scenarios of this an exception review is required between Customer Salesforce IT team and the project in question.

###	Excessive Method Length

Violations of this rule usually indicate that the method is doing too much. Try to reduce the method size by creating helper methods and removing any copy/pasted code. Upon review the limit in the scanning tool has been increased from the default of 100 to 300.

### NCSS Method Count

This rule uses the NCSS (Non commenting source statements) algorithm to determine the number of lines of code for a given method. NCSS ignores comments and counts actual statements. Using this algorithm, lines of code that are split are counted as one. Upon review the level in the scanning tool has been increased from a default of 100 to 300.
### Too Many Methods

A class with too many methods is probably a good suspect for refactoring, in order to reduce its complexity and find a way to have more fine grained objects. Upon review the level in the scanning tool has been increased from a default of 10 to 25.

### Avoiding Non-Consecutive Heading Tags

Heading tags are used by search engines and screen reader software to construct an outline of the page. Starting at < h1 > and not skipping any level eases this automatic construction.
Upon review the level in the scanning tool has been changed from MAJOR to Info.

###	Unused Formal Parameter

Avoid passing parameters to methods or constructors and then not using those parameters.
Upon review the level in the scanning tool has been changed from MAJOR to Info.

###   NPath (Cyclomatic) Complexity

The NPath complexity of a method is the number of acyclic execution paths through that method. A threshold of 200 is generally considered where measures should be taken to reduce complexity. A high value makes testing and maintenance harder so code should be refactored if the complexity level is too high.
Upon review, the level in the scanning tool has been changed from the default of 200 to the new value of 300.

###  Test Code Coverage

As mentioned above best practice states that test code coverage should be targeting 95%.In the Customer environment it has been decided that this target is reduced to 90% for all projects.


